{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to surbhi.jain@sjsu.edu and will expire on November 21, 2018.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1511465701.log\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def score(df_true, df_pred):\n",
    "\n",
    "    df = pd.concat([df_pred,\n",
    "                    df_true], axis=1)\n",
    "\n",
    "    g = df.groupby('user_id')\n",
    "\n",
    "    top_5 = g.pred_rating.apply(\n",
    "        lambda x: x >= x.quantile(.95)\n",
    "    )\n",
    "\n",
    "    return df_true[top_5==1].mean()['true_rating']\n",
    "\n",
    "def extract_key_words(text):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "    for i in chunked:\n",
    "        if type(i) == Tree:\n",
    "            current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return continuous_chunk\n",
    "    \n",
    "\n",
    "def clean_joke(joke):\n",
    "    joke = re.sub(r'([^\\.\\s\\w]|_)+', '', joke).replace(\".\", \". \")\n",
    "    joke = joke.replace('\\r', '') \n",
    "    joke = joke.replace('\\n', '')\n",
    "    joke = joke.replace('<br />', '')\n",
    "    joke = joke.replace('<p>', '')\n",
    "    joke = joke.replace('&quot;', '')\n",
    "    joke = joke.replace('&#039;', '')\n",
    "    joke = \" \".join(extract_key_words(joke))\n",
    "    return joke\n",
    "\n",
    "def load_joke_classes_and_text():\n",
    "    data = pd.read_csv(\"../data/Jokes_labelling.txt\", delimiter=\"\\t\")\n",
    "    data['Jokes'] = data['Jokes'].map(lambda j: clean_joke(j))\n",
    "    data.drop('joke_category', axis=1, inplace=True)\n",
    "    cat_feats = pd.get_dummies(data['joke_category_reduced'], prefix='cat')\n",
    "    data = pd.concat([data['joke_id'], data['Jokes'], cat_feats], axis=1)\n",
    "    \n",
    "    data_sf = gl.SFrame(data)\n",
    "    \n",
    "    return data_sf\n",
    "    \n",
    "\n",
    "def load_data():\n",
    "    # Input data\n",
    "    sf = gl.SFrame(\"../data/ratings.dat\", format='tsv')\n",
    "\n",
    "    # Data to test predictions on\n",
    "    df_sample = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "    sf_sample = gl.SFrame(df_sample)\n",
    "\n",
    "    return sf, sf_sample, df_sample\n",
    "\n",
    "def load_joke_classes_text_and_glove_vectors():\n",
    "    id_vectors = pd.read_csv(\"../data/Jokes_id_with_vectors.txt\", delimiter=\"\\t\")\n",
    "    data = pd.read_csv(\"../data/Jokes_labelling.txt\", delimiter=\"\\t\")\n",
    "    cat_feats = pd.get_dummies(data['joke_category_reduced'], prefix='cat')\n",
    "    \n",
    "\n",
    "    all_data = pd.merge(data, id_vectors, on='joke_id', how='inner').set_index('joke_id').reset_index()\n",
    "    \n",
    "    X = pd.concat([all_data, cat_feats], axis=1)\n",
    "    #print X.columns\n",
    "    #print X.describe(include='all')\n",
    "    X.drop(['Jokes','joke_category', 'joke_category_reduced','Unnamed: 301'], axis=1, inplace=True)\n",
    "    X = X.fillna(0)\n",
    "    X = gl.SFrame(X)\n",
    "    \n",
    "    cat_feats['joke_id'] = range(1,151)\n",
    "    cat_feats = gl.SFrame(cat_feats)\n",
    "    return X, cat_feats\n",
    "\n",
    "def recommendation_modules(sf, num_factors, regularization = None):\n",
    "    \n",
    "    #joke_data_and_category = load_joke_classes_and_text()\n",
    "    joke_vector_and_cat, joke_cat = load_joke_classes_text_and_glove_vectors()\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    ranking_model = gl.recommender.ranking_factorization_recommender.create(observation_data=sf,\n",
    "                                                     user_id=\"user_id\",\n",
    "                                                     item_id=\"joke_id\",\n",
    "                                                     target='rating',\n",
    "                                                     solver='auto',\n",
    "                                                     num_factors = num_factors,\n",
    "                                                     regularization = regularization,\n",
    "                                                     verbose = False,\n",
    "                                                     random_seed = 42)\n",
    "    \n",
    "    factorization_model = gl.recommender.factorization_recommender.create(observation_data=sf,\n",
    "                                                     user_id=\"user_id\",\n",
    "                                                     item_id=\"joke_id\",\n",
    "                                                     target='rating',\n",
    "                                                     solver='auto',\n",
    "                                                     num_factors = num_factors,\n",
    "                                                     regularization = regularization,\n",
    "                                                     verbose = False,\n",
    "                                                     random_seed = 42)\n",
    "    '''\n",
    "    item_sim_model = gl.recommender.item_similarity_recommender.create(observation_data=sf,\n",
    "                                                     user_id=\"user_id\",\n",
    "                                                     item_id=\"joke_id\",\n",
    "                                                     target='rating',\n",
    "                                                     #solver='auto',\n",
    "                                                     #num_factors = num_factors,\n",
    "                                                     #regularization = regularization,\n",
    "                                                     verbose = False,\n",
    "                                                     #random_seed = 42, \n",
    "                                                     similarity_type='jaccard')\n",
    "    \n",
    "    item_sim_model_with_categories = gl.recommender.item_similarity_recommender.create(observation_data=sf,\n",
    "                                                     user_id=\"user_id\",\n",
    "                                                     item_id=\"joke_id\",\n",
    "                                                     target='rating',\n",
    "                                                     #solver='auto',\n",
    "                                                     #num_factors = num_factors,\n",
    "                                                     #regularization = regularization,\n",
    "                                                     verbose = False,\n",
    "                                                     #random_seed = 42,\n",
    "                                                     similarity_type='jaccard',\n",
    "                                                     item_data=  joke_cat                                      \n",
    "                                                     )\n",
    "    item_sim_model_with_vectors_and_categories = gl.recommender.item_similarity_recommender.create(observation_data=sf,\n",
    "                                                     user_id=\"user_id\",\n",
    "                                                     item_id=\"joke_id\",\n",
    "                                                     target='rating',\n",
    "                                                     #solver='auto',\n",
    "                                                     #num_factors = num_factors,\n",
    "                                                     #regularization = regularization,\n",
    "                                                     verbose = False,\n",
    "                                                     #random_seed = 42,\n",
    "                                                     similarity_type='jaccard',\n",
    "                                                     item_data=  joke_vector_and_cat                                      \n",
    "                                                     )\n",
    "    \n",
    "    \n",
    "    \n",
    "    return item_sim_model, item_sim_model_with_categories, item_sim_model_with_vectors_and_categories\n",
    "    #return ranking_model, factorization_model, item_sim_model_pearson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/ckhatri/Downloads/joke_project/data/ratings.dat</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/ckhatri/Downloads/joke_project/data/ratings.dat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.536439 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.536439 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,float]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/ckhatri/Downloads/joke_project/data/ratings.dat</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/ckhatri/Downloads/joke_project/data/ratings.dat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1218325 lines in 0.72803 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1218325 lines in 0.72803 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Factors: 2  Score: 1.53297483766\n",
      "Num Factors: 2  Score: 1.39583333333\n",
      "Num Factors: 2  Score: 1.38078327922\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Factors: 4  Score: 1.561620671\n",
      "Num Factors: 4  Score: 1.37736742424\n",
      "Num Factors: 4  Score: 1.4053030303\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Factors: 8  Score: 1.51234442641\n",
      "Num Factors: 8  Score: 1.47602137446\n",
      "Num Factors: 8  Score: 1.38876488095\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Factors: 16  Score: 1.60044642857\n",
      "Num Factors: 16  Score: 1.37432359307\n",
      "Num Factors: 16  Score: 1.3304586039\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Factors: 32  Score: 1.50656114719\n",
      "Num Factors: 32  Score: 1.39174107143\n",
      "Num Factors: 32  Score: 1.34307359307\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Factors: 50  Score: 1.57727949134\n",
      "Num Factors: 50  Score: 1.29464285714\n",
      "Num Factors: 50  Score: 1.34591450216\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Factors: 64  Score: 1.49188311688\n",
      "Num Factors: 64  Score: 1.28121617965\n",
      "Num Factors: 64  Score: 1.41734307359\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Factors: 80  Score: 1.51924377706\n",
      "Num Factors: 80  Score: 1.37489853896\n",
      "Num Factors: 80  Score: 1.32700892857\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Factors: 100  Score: 1.58850784632\n",
      "Num Factors: 100  Score: 1.38274485931\n",
      "Num Factors: 100  Score: 1.39126758658\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (9,) and (27,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b6d4a2ae1571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'Num Factors:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' Score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_factors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Latent Features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ckhatri/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3316\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3318\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3319\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ckhatri/anaconda/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ckhatri/anaconda/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ckhatri/anaconda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ckhatri/anaconda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ckhatri/anaconda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 244\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (9,) and (27,)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sf, sf_sample, df_sample = load_data()\n",
    "\n",
    "    training_data, validation_data = gl.recommender.util.random_split_by_user(sf, 'user_id', 'joke_id')\n",
    "\n",
    "    df_true = pd.DataFrame()\n",
    "    df_pred = pd.DataFrame()\n",
    "\n",
    "    df_true['user_id'] = validation_data['user_id']\n",
    "    df_true['joke_id'] = validation_data['joke_id']\n",
    "\n",
    "    df_true['true_rating'] = validation_data['rating']\n",
    "\n",
    "    # Plot scores vs num_factors\n",
    "    num_factors = range(2,100)\n",
    "    num_factors = [2, 4, 8, 16, 32, 50, 64, 80, 100]\n",
    "    #num_factors = [2, 4]\n",
    "    scores = []\n",
    "    for n in num_factors:\n",
    "        for m in recommendation_modules(training_data, num_factors = n):\n",
    "            #m = create_factorization_recommender(training_data, num_factors = n)\n",
    "            df_pred['pred_rating'] = m.predict(validation_data)\n",
    "            rc = score(df_true, df_pred)\n",
    "            scores.append(rc)\n",
    "            print 'Num Factors:', n, ' Score:', rc\n",
    "        print \"\\n\\n\\n\"\n",
    "    plt.plot(num_factors, scores)\n",
    "    plt.xlabel('Number of Latent Features')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Score vs Number of Latent Features')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
